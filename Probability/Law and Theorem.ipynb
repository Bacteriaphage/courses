{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weak law of large number\n",
    "\n",
    "### Chebyshev's inequality\n",
    "\n",
    "$$\\sigma^2 = \\int (x-\\mu)^2f_X(x)dx$$\n",
    "$$\\ge \\int_{-\\infty}^{\\mu-c} (x-\\mu)^2f_X(x)dx+\\int_{\\mu+c}^{\\infty} (x-\\mu)^2f_X(x)dx$$\n",
    "$$\\ge \\int_{-\\infty}^{\\mu-c} c^2f_X(x)dx+\\int_{\\mu+c}^{\\infty} c^2f_X(x)dx$$\n",
    "$$=c^2P(\\vert X-\\mu\\vert \\ge c)$$\n",
    "\n",
    "$$P(\\vert X-\\mu\\vert\\ge c) \\le \\frac{\\sigma^2}{c^2}$$\n",
    "$$P(\\vert X-\\mu\\vert\\ge k\\sigma) \\le \\frac{1}{k^2}$$\n",
    "\n",
    "### sample mean and true mean\n",
    "\n",
    "As we know the true mean only exists when number of sample is an extremely large number. But how can some limited sample space shows mean?\n",
    "\n",
    "Suppose we have n samples and each sample is independent with each other, then we have n independent random variables. We can use it to build a sample mean:\n",
    "\n",
    "$$M_n = \\frac{X_1+X_2+...+X_n}{n}$$\n",
    "\n",
    "$M$ of course is also a random varible. Then we will have:\n",
    "\n",
    "$$E[M] = \\Sigma_i^n E[\\frac{X_i}{n}] = E[X]$$\n",
    "\n",
    "$$var(M) = \\Sigma_i^n var[\\frac{X_i}{n}] = \\frac{var(X)}{n}$$\n",
    "\n",
    "As we can see, when n becomes larger and larger, the variance of M will close to 0, that mean the $E[M]$ will be more and more close to true mean. Apply Chebyshev's inequality:\n",
    "\n",
    "$$P(\\vert M_n-\\mu\\vert\\ge \\epsilon) \\le \\frac{var(M)}{\\epsilon^2} = \\frac{var(X)}{n\\epsilon^2}$$\n",
    "\n",
    "#### law of large number\n",
    "$$lim_{n->\\infty} P(\\vert M_n-\\mu\\vert\\ge \\epsilon) = 0$$\n",
    "\n",
    "So $M_n$ converges in probability to $\\mu$\n",
    "\n",
    "### design poll questionaire\n",
    "\n",
    "We want to make a survey and check the is the fraction $f$ of people choosing 1, we want to have 95% condidence of less than 1% error in our poll design, how many questionaire we need to send out?\n",
    "\n",
    "$$P(\\vert M_n-f\\vert\\ge 0.01) \\le 0.05$$\n",
    "\n",
    "$$P(\\vert M_n-f\\vert\\ge 0.01) = \\frac{var(X)}{n(0.01)^2}$$\n",
    "\n",
    "Since X is an Bernuolli random variable which has var as $f(1-f)$, we make the most conservative estimation as f=0.5, var=0.25, then:\n",
    "\n",
    "$$P(\\vert M_n-f\\vert\\ge 0.01) = \\frac{var(X)}{n(0.01)^2} \\le \\frac{1}{4n(0.01)^2} \\le 0.05$$\n",
    "\n",
    "$$n \\ge 50000$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central limit theorem\n",
    "\n",
    "As we know in above sample mean case, the variance will be smaller and smaller when n goes large, how can we make up a random variable depending on sum of random varibale and makes it have constant variance?\n",
    "\n",
    "$$Z_n = \\frac{S_n - E[S_n]}{\\sigma_{S_n}}$$\n",
    "where $S_n = X_1+X_2+...+X_n$\n",
    "$$Z_n = \\frac{S_n - nE[X]}{\\sqrt{n}\\sigma}$$\n",
    "We can see that $Z_n$ is a random variable which has $E[Z_n]=0$ and $var(Z_n)=1$\n",
    "\n",
    "Assume Z is a standard normal random variable, then, when n goes to infinity:\n",
    "\n",
    "$$P(Z_n \\le c) = P(Z \\le c)$$\n",
    "\n",
    "The theorem is true no matter what distribution X has, it only depends on means and variences\n",
    "\n",
    "Be careful, the central limit theorem is only for CDF, that means the PDF/PMF might not be the same as standard normal variable.\n",
    "\n",
    "An experimental observation is when X is close to a normal distribution, then small central limit theorem get bring us correct answer even n is small, but if X is far from a nromal distribution, then n needs to large to ensure the theorem gives us the correct answer.\n",
    "\n",
    "### revisit poll questionaire\n",
    "\n",
    "We want $P(\\vert M_n-f\\vert \\ge 0.01)$, then our goal is:\n",
    "\n",
    "$$\\vert \\frac{S_n-nf}{n}\\vert \\ge 0.01$$\n",
    "\n",
    "$$\\vert \\frac{S_n-nf}{\\sqrt{n}\\sigma}\\vert \\ge \\frac{0.01\\sqrt{n}}{\\sigma}$$\n",
    "\n",
    "so:\n",
    "$$P(\\vert M_n-f\\vert \\ge 0.01) \\approx P(\\vert Z\\vert \\ge \\frac{0.01\\sqrt{n}}{\\sigma}) \\le P(\\vert Z\\vert \\ge 0.02\\sqrt{n})$$\n",
    "Then because we have 95% confidence, we can calculate n, which gives us 9604"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson vs. Normal.\n",
    "\n",
    "Assume we have a Possion process in time interval [0, 1] has arrival rate $\\lambda$, we split it equally to n sub-slot, we have:\n",
    "\n",
    "$$X = X_1 + X_2 + ... X_n$$\n",
    "\n",
    "we know for a Poisson process, $E[X] = \\lambda$ and we also have $var$, If we apply central limit theorem to it, X should be a normal distribution, which gives us a huge contradiction, a Poisson distribution is a normal distribution!\n",
    "\n",
    "The subtle point here is, in central limit theorem, each $X_i$ should be fixed and when n goes large, we can use the theorem, but in this case, when n goes large, $X_i$ goes small, so we cannot apply the theorem to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
